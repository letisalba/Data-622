---
title: "Data 622 - Homework 1"
author: "Leticia Salazar"
date: "October 8, 2023"
output: 
  pdf_document:
    latex_engine: xelatex
    dev: cairo_pdf
  html_document:
    theme: sandstone
    highlight: haddock
---

```{r setup, include=FALSE, out.width="50%"}
knitr::opts_chunk$set(echo = TRUE)
```
$~$

#### Pre-work
1. Visit the following website and explore the range of sizes of this dataset (from 100 to 5 million records):
https://excelbianalytics.com/wp/downloads-18-sample-csv-files-data-sets-for-testing-sales/ or
(new) https://www.kaggle.com/datasets
2. Select 2 files to download
Based on your computer's capabilities (memory, CPU), select 2 files you can handle (recommended one small, one large)
3. Download the files
4. Review the structure and content of the tables, and think about the data sets (structure, size, dependencies, labels, etc)
5. Consider the similarities and differences in the two data sets you have downloaded
6. Think about how to analyze and predict an outcome based on the datasets available
7. Based on the data you have, think which two machine learning algorithms presented so far could be used to analyze the data

$~$

#### Load Libraries:
Below are the libraries used to complete this assignment
```{r, cache=FALSE, results=FALSE, warning=FALSE, comment=FALSE, warning=FALSE} 
library(tidyverse) # data prep
library(skimr) # data prep
#install.packages('rpart.plot') # must install if not already
library(rpart) # decision tree package
library(rpart.plot) # decision tree display package
library(knitr) # kable function for table
library(tidyr) # splitting data
library(ggplot2) # graphing
library(hrbrthemes) # chart customization
library(gridExtra) # layering charts
library(stringr) # data prep
library(tidymodels) # predictions
```

$~$

#### Load Data:
The data chosen from Excel BI Analytics were the 100 sales records for the small and 5000 sales records for the large. The data sets are included in my [GitHub](https://github.com/letisalba/Data-622/tree/master/Homework-1/csv) and read into R.
```{r, loading data, echo = FALSE}
# Read the data into R
small_df <- read.csv("https://raw.githubusercontent.com/letisalba/Data-622/master/Homework-1/csv/100%20Sales%20Records.csv")
large_df <- read.csv("https://raw.githubusercontent.com/letisalba/Data-622/master/Homework-1/csv/5000%20Sales%20Records.csv")
```

$~$

### The Data:

Both of these data sets contain the same columns with the minor difference of the total of records. The columns are as follows:

* Region: region of sale
* Country: country of sale
* Item Type: item sold
* Sales Channel: online or offline sale
* Order Priority: priority of the order "L"- Low, "M"- Medium, "H"- High, "C"- Critical
* Order Date: date of the order
* Order ID: ID of the order
* Ship Date: date the order was shipped 
* Units Sold: amount of units sold
* Unit Cost: cost of the order 
* Total Revenue: total revenue of the order
* Total Cost: total cost of the order
* Total Profit: total profit of the order

$~$

**The small data set:**
```{r, echo=FALSE, kable.opts=list(caption="data frame is now printed using `kable`.")}
# display the small dataset
kable(head(small_df), align = "l", table.attr = "style='width:30%;'")
```

$~$

**The large data set:**
```{r, echo=FALSE}
# display the largde dataset
kable(head(large_df), align = "l", table.attr = "style='width:10%;'")
```

$~$

### Data Exploration:

Let's explore the data sets; first the `small_df` data set, using the `skimr` library we can obtain quick summary statistics beyond the `summary()`. We notice that we have 14 variables split into 7 character and 7 numeric. There seems to be no missing values, so this will have a simple preparation before we build our models.
```{r, echo=FALSE}
# summary of the small dataset
skim(small_df)
```
$~$

##### Let's take a look at the distributions of the numeric variables for the small data set:
```{r, fig.height=12, fig.width=12, warning=FALSE, echo=FALSE, message=FALSE, fig.align='center'}
# histogram for units sold of small dataset
p1 <- small_df %>% 
ggplot( aes(x=Units.Sold)) +
    geom_histogram(fill="#69b3a2", color="#e9ecef", alpha=0.8) +
    ggtitle("Small_df Units Sold Histogram") +
    theme_ipsum() +
    theme(
      plot.title = element_text(size=15)
    )

# histogram for unit price of small dataset
p2 <- small_df %>% 
ggplot( aes(x=Unit.Price)) +
    geom_histogram(fill="#69a0b3", color="#e9ecef", alpha=0.8) +
    ggtitle("Small_df Unit Price Histogram") +
    theme_ipsum() +
    theme(
      plot.title = element_text(size=15)
    )

# histogram for unit cost of small dataset
p3 <- small_df %>% 
ggplot( aes(x=Unit.Cost)) +
    geom_histogram(fill="#696fb3", color="#e9ecef", alpha=0.8) +
    ggtitle("Small_df Unit Cost Histogram") +
    theme_ipsum() +
    theme(
      plot.title = element_text(size=15)
    )

# histogram for Total Revenue of small dataset
p4 <- small_df %>% 
ggplot( aes(x=Total.Revenue)) +
    geom_histogram(fill="#b369ae", color="#e9ecef", alpha=0.8) +
    ggtitle("Small_df Total Revenue Histogram") +
    theme_ipsum() +
    theme(
      plot.title = element_text(size=15)
    )

# histogram for Total Cost of small dataset
p5 <- small_df %>% 
ggplot( aes(x=Total.Cost)) +
    geom_histogram(fill="#77b369", color="#e9ecef", alpha=0.8) +
    ggtitle("Small_df Total Cost Histogram") +
    theme_ipsum() +
    theme(
      plot.title = element_text(size=15)
    )

# histogram for Total Profit of small dataset
p6 <- small_df %>% 
ggplot( aes(x=Total.Profit)) +
    geom_histogram(fill="#b37e69", color="#e9ecef", alpha=0.8) +
    ggtitle("Small_df Total Profit Histogram") +
    theme_ipsum() +
    theme(
      plot.title = element_text(size=15)
    )

# displaying the histograms
par(mfrow = c(3, 3))
grid.arrange(p1,p2,p3,p4,p5,p6)
```

##### Categorical variables visualization for the small dataset:
```{r, fig.height=12, fig.width=12, warning=FALSE, echo=FALSE, message=FALSE, fig.align='center'}
# bar charts for the categorical variables

# Region Bar chart
p7 <- small_df %>%
  ggplot(aes(x=Region)) +
  geom_bar(fill="#69b3a2") +
  coord_flip() +
  ggtitle("Region Bar Chart") +
    theme_ipsum() +
    theme(
      plot.title = element_text(size = 15)
    )

# Item Type Bar chart
p8 <- small_df %>% 
  ggplot(aes(x=Item.Type)) +
  geom_bar(fill="#69a0b3") +
  ggtitle("Item Type Bar Chart") +
    theme_ipsum() +
    theme(
      plot.title = element_text(size = 15), 
      axis.text.x = element_text(angle = 45, vjust = 0.5, hjust=1)
    )

# Sales Channel Bar chart  
p9 <- small_df %>% 
  ggplot(aes(x=Sales.Channel)) +
  geom_bar(fill="#696fb3") +
  ggtitle("Sales Channel Bar Chart") +
    theme_ipsum() +
    theme(
      plot.title = element_text(size = 15)
    )

# Order Priority Bar chart  
p10 <- small_df %>% 
  ggplot(aes(x=Order.Priority)) +
  geom_bar(fill="#b369ae") +
  scale_x_discrete(labels=c('Critical', 'High', 'Low', 'Medium')) +
  ggtitle("Order Priority Bar Chart") +
    theme_ipsum() +
    theme(
      plot.title = element_text(size = 15)
    )
  
# displaying the bar charts
par(mfrow = c(3, 3))
grid.arrange(p7,p8,p9,p10)
```

$~$

Now, the `large_df` dataset is composed of 5000 values of the same 14 variables as the `small` data set. It also has 7 character and 7 numeric variables with no missing values.
```{r, echo=FALSE}
# summary of the large dataset
skim(large_df)
```
$~$

##### Visualizations of the numeric variable distributions of the large dataset:
```{r, fig.height=12, fig.width=12, warning=FALSE, echo=FALSE, message=FALSE, fig.align='center'}
# histogram for units sold of small dataset
p11 <- large_df %>% 
ggplot( aes(x=Units.Sold)) +
    geom_histogram(fill="#69b3a2", color="#e9ecef", alpha=0.8) +
    ggtitle("Large Dataset Units Sold Histogram") +
    theme_ipsum() +
    theme(
      plot.title = element_text(size=15)
    )

# histogram for unit price of small dataset
p12 <- large_df %>% 
ggplot( aes(x=Unit.Price)) +
    geom_histogram(fill="#69a0b3", color="#e9ecef", alpha=0.8) +
    ggtitle("Large Dataset Unit Price Histogram") +
    theme_ipsum() +
    theme(
      plot.title = element_text(size=15)
    )

# histogram for unit cost of small dataset
p13 <- large_df %>% 
ggplot( aes(x=Unit.Cost)) +
    geom_histogram(fill="#696fb3", color="#e9ecef", alpha=0.8) +
    ggtitle("Large Dataset Unit Cost Histogram") +
    theme_ipsum() +
    theme(
      plot.title = element_text(size=15)
    )

# histogram for Total Revenue of small dataset
p14 <- large_df %>% 
ggplot( aes(x=Total.Revenue)) +
    geom_histogram(fill="#b369ae", color="#e9ecef", alpha=0.8) +
    ggtitle("Large Dataset Total Revenue Histogram") +
    theme_ipsum() +
    theme(
      plot.title = element_text(size=15)
    )

# histogram for Total Cost of small dataset
p15 <- large_df %>% 
ggplot( aes(x=Total.Cost)) +
    geom_histogram(fill="#77b369", color="#e9ecef", alpha=0.8) +
    ggtitle("Large Dataset Total Cost Histogram") +
    theme_ipsum() +
    theme(
      plot.title = element_text(size=15)
    )

# histogram for Total Profit of small dataset
p16 <- large_df %>% 
ggplot( aes(x=Total.Profit)) +
    geom_histogram(fill="#b37e69", color="#e9ecef", alpha=0.8) +
    ggtitle("Large Dataset Total Profit Histogram") +
    theme_ipsum() +
    theme(
      plot.title = element_text(size=15)
    )

# displaying the histograms
par(mfrow = c(3, 3))
grid.arrange(p11,p12,p13,p14,p15,p16)
```

$~$

##### Now let's look at the categorical variables:

```{r, fig.height=12, fig.width=12, warning=FALSE, echo=FALSE, message=FALSE, fig.align='center'}
# Region Barchart
p17 <- large_df %>% 
  ggplot(aes(x=Region)) +
  geom_bar(fill="#69b3a2") +
  coord_flip() +
  ggtitle("Region Bar Chart") +
    theme_ipsum() +
    theme(
      plot.title = element_text(size = 15)
    )

# Item Type Barchart
p18 <- large_df %>% 
  ggplot(aes(x=Item.Type)) +
  geom_bar(fill="#696fb3") +
  ggtitle("Item Type Bar Chart") +
    theme_ipsum() +
    theme(
      plot.title = element_text(size = 15), 
      axis.text.x = element_text(angle = 45, vjust = 0.5, hjust=1)
    )

# Sales Channel Barchart  
p19 <- large_df %>% 
  ggplot(aes(x=Sales.Channel)) +
  geom_bar(fill="#b369ae") +
  ggtitle("Sales Channel Bar Chart") +
    theme_ipsum() +
    theme(
      plot.title = element_text(size = 15)
    )

# Order Priority Barchart  
p20 <- large_df %>% 
  ggplot(aes(x=Order.Priority)) +
  geom_bar(fill="#77b369") +
  ggtitle("Order Priority Bar Chart") +
  scale_x_discrete(labels=c('Critical', 'High', 'Low', 'Medium')) +
    theme_ipsum() +
    theme(
      plot.title = element_text(size = 15)
    )
  
# displaying the bar charts
par(mfrow = c(3, 2))
grid.arrange(p17,p18,p19,p20)
```

##### Some notes on the visualizations above: 

*  The distributions for both small and large datasets are fairly similar with the exception of `Units.Sold`. The large data set has a more unform distribution for this variable compared to the small dataset.
* There is no pattern for `Unit.Price` and `Unit.Cost` in both datasets
* Both data sets have the variables `Total.Revenue`, `Total.Cost` and `Total.Profit` histograms right skewed
* For the categotical variables, both Sub-Saharan African and Europe are the top 2 largest Region where the sales are from for both datasets with North American being the region with the lowest sales
* `Sales.Channel` variable are even for both datasets
* The `Item.Type` variable in the small dataset has top 3 items as: Clothes, Cosmetics and Office Supplies while the large dataset has Beverages, Fruits and Baby Food as it's top 3 items.
* In terms of the `Order.Priority`, the small dataset's "High" and "Low" priorities have the highest frequency count as opposed to the larger dataset which has "Medium" and "High" with the largest frequency count.

$~$

### Data Preparation:

Now that I've visualized the data it's time to make some changes to the variables. First, convert the categorical values into `as.factor` and convert the two columns containing dates to `as.Date` to be able to manipulate. I'll drop the `Order.ID` column as it is not needed with our model. Below are the results:
```{r, echo=FALSE}
# small data set

# converting to as.factor
small_df$Region <- as.factor(small_df$Region)
small_df$Country <- as.factor(small_df$Country)
small_df$Item.Type <- as.factor(small_df$Item.Type)
small_df$Sales.Channel <- as.factor(small_df$Sales.Channel)
small_df$Order.Priority <- as.factor(small_df$Order.Priority)

# converting to as.Date
small_df$Order.Date <- as.Date(small_df$Order.Date, "%m/%d/%Y")
small_df$Ship.Date <- as.Date(small_df$Ship.Date, "%m/%d/%Y")

# dropping "Order.ID" column
small_df <- small_df[,-c(7)]

# large data set

# converting to as.factor
large_df$Region <- as.factor(large_df$Region)
large_df$Country <- as.factor(large_df$Country)
large_df$Item.Type <- as.factor(large_df$Item.Type)
large_df$Sales.Channel <- as.factor(large_df$Sales.Channel)
large_df$Order.Priority <- as.factor(large_df$Order.Priority)

# converting to as.Date
large_df$Order.Date <- as.Date(large_df$Order.Date, "%m/%d/%Y")
large_df$Ship.Date <- as.Date(large_df$Ship.Date, "%m/%d/%Y")

# dropping "Order.ID" column
large_df <- large_df[,-c(7)]
```

$~$

**Small dataset:**
```{r, echo=FALSE}
kable(head(small_df))
```

$~$

**Large dataset:**
```{r, echo=FALSE}
kable(head(large_df))
```

$~$

### Model Selection:

While exploring the data I've noticed that my data doesn't have labels by default but more so can be defined based on the analysis being performed. There are two labels I can visualize `Order.Priority` or `Total.Profit`. With `Order.Priority` as my target variable I can predict which category a new sale would fall into "C", "H", "L", or "M".  Variables such as `Item.Type`, `Units.Sold` and `Total.Cost` can affect the level in priority of a new sale. With `Total.Profit` as my target variable I can consider all the other variables to see how it affects sales profits.

Decision Trees can be a suitable choice for predicting a categorical target variable like `Order.Priority`. They are a type of supervised machine learning algorithm that can handle both classification and regression tasks. In this case, I chose to classify orders into different priority levels and have opted to use a decision tree model.

Some considerations for using a decision tree model for predicting `Order.Priority`:

* Well-suited for predicting categorical target variables, such as priority levels (critical, low, medium, high).
* Highly interpretable models that can easily visualize the tree structure and understand the rules that lead to a particular priority classification. 
* Can provide information about feature importance, helping you identify which factors have the most significant influence on order priority.
* Can capture nonlinear relationships between input features and the target variable, which can be valuable if the relationship between order attributes and priority is not linear.

There are also some considerations and potential challenges when using decision trees:

* Decision trees can be prone to overfitting, where the model captures noise in the training data and performs poorly on unseen data.
* If the dataset has imbalanced class distributions for order priorities (e.g., a lot of "low" priority orders and few "high" priority orders), these will need to be addressed during model training and evaluation.
* The quality of your input data, including missing values and outliers, can affect the performance of a decision tree model.
* To achieve the best performance with a decision tree, you may need to tune hyperparameters, such as the maximum depth of the tree or the minimum number of samples required to split a node.

$~$

### Model Building:

First, we start by splitting both datasets into the standard ratio 75:25
```{r, echo=FALSE}
# Split the data into training and testing sets

# create same random numbers for reproduction
set.seed(123)

# small data set splitting
small_df_split <- initial_split(small_df, prop = 0.75)
small_train <- training(small_df_split)
small_test <- testing(small_df_split)
#head(small_train)

# large data set splitting
large_df_split <- initial_split(large_df, prop = 0.75)
large_train <- training(large_df_split)
large_test <- testing(large_df_split)
#head(large_train)
```


Now we can start the decision tree for the small data set using the `rpart` function and setting `Order.Priority` as our target variable followed by the rest of the variables. The results are below:

```{r, echo=FALSE}
# create the decision tree
small_df_model <- rpart(Order.Priority ~ Region + Item.Type + Sales.Channel + Order.Date + 
                          Ship.Date + Units.Sold + Total.Revenue + Total.Cost + Total.Profit,
                        method = "class", data = small_train)

# display the decision tree
prp(small_df_model, extra=1, faclen=0,  nn=T, box.palette="Blues")
```

To test the above model I used the `small_df` testing data to create the prediction table below:
```{r, echo=FALSE}
# creating our prediction
small_df_prediction <- predict(small_df_model, small_test, type = "class")
small_df_prediction <- table(small_test$Order.Priority, small_df_prediction)

# display the table
kable(small_df_prediction, align = "lcccc")
```

and checking the accuracy of the model using the predicted values alongside the `small_test` data which is 44%:
```{r, echo=FALSE}
# Testing the accuracy of the model
kable(sum(diag(small_df_prediction)) / nrow(small_test), caption = "Accuracy", align = "l")
```

$~$

Now that the `small_df` has been completed it's time to do the `large_df`. Same as before, create the decision tree with `Order.Priority` as my target variable. The results are below:

```{r, echo=FALSE}
# create the decision tree
large_df_model <- rpart(Order.Priority ~ Region + Item.Type + Sales.Channel + Order.Date + 
                          Ship.Date + Units.Sold + Total.Revenue + Total.Cost + Total.Profit,
                        method = "class", data = large_train)

# display the decision tree
prp(large_df_model, extra=1, faclen=0,  nn=T, box.palette="Greens")
```

Testing the model against the `large_test` data:
```{r, echo=FALSE}
# creating our prediction
large_df_prediction <- predict(large_df_model, large_test, type = "class")
large_df_prediction <- table(large_test$Order.Priority, large_df_prediction)

# display the table
kable(large_df_prediction, align = "lcccc")
```

and now to check the accuracy of the model which is 25.7%:
```{r, echo=FALSE}
# Testing the accuracy of the model
kable(sum(diag(large_df_prediction)) / nrow(large_test), caption = "Accuracy", align = "l")
```

$~$

I did not expect the decision tree for the larger dataset to be this small along with the accuracy compared to the small dataset. After some research I found some parameters I could improve on the `rpart` function to improve the model and it's accuracy. Below are the results:
```{r, echo=FALSE}
# create the decision tree for the second model
large_df_model2 <- rpart(Order.Priority ~ Region + Item.Type + Sales.Channel + Order.Date +
                          Ship.Date + Units.Sold + Total.Revenue + Total.Cost + Total.Profit, 
                        method = "class", data = large_train, 
                        control= rpart.control(minsplit = 4, minbucket = round(5 / 3), maxdepth = 3, cp = 0))

# display the decision tree of the second model
prp(large_df_model2, extra=1, faclen=0,  nn=T, box.palette="Purple")
```

Now that I have a better decision tree I test the above model using our `large_df_model2` and `large_test` testing data:
```{r, echo=FALSE}
# creating our prediction for the second model
large_df_prediction2 <- predict(large_df_model2, large_test, type = "class")
large_df_prediction2 <- table(large_test$Order.Priority, large_df_prediction2)

# display the table of the second model
kable(large_df_prediction2, align = "lcccc")
```


and finally checking the accuracy of the second model; we see the accuracy is only 25.6% which is less than the first model. There wasn't much improvement in accuracy but we note the changes in the nodes of the decision trees.
```{r, echo=FALSE}
# Testing the accuracy of the second model
kable(sum(diag(large_df_prediction2)) / nrow(large_test), caption = "Accuracy", align = "l")
```

$~$

### Conclusion:

Based on the results for both `small_df` and `large_df` although the smaller data set has a higher accuracy than the larger dataset it is still not sufficient enough to make business decisions. The models could use some improvements to make it more valuable. For the large dataset, changing the parameters didn't improve the accuracy of the model but it was a lower percentage than the small dataset accuracy. It's safe to assume that using too much or too little data can have it's challenges and lead to some errors. 

For instance using too much data can lead to:

* being computationally expensive and time-consuming, especially for complex models like deep neural networks

* there's a risk of overfitting where the model learns to memorize the training data rather than generalizing from it leading to poor performance

* not ensuring data quality, where the larger data set can contain noise and outliers that can affect the model's performance

Too little data can lead to:

* a model struggling to learn complex patterns and generalize effectively therefore, it's performance may not be representative of the underlying relationships

* overfitting to the noise of the dataset resulting in a model that performs well on the training data but poorly on new data introduced

* reduction of the variables used in the analysis to prevent overfitting that can lead to losing important information

By choosing to create decision trees for these two datasets I wanted to predict `Order.Priority` to visualize how the outcomes "Critical", "Low", "Medium" and "High" are affected by the other variables. Based on my findings I conclude that a decision tree was probably not the best route to take for these two datasets and could have used other sizes in small and large datasets to view bigger differences between the models.

$~$

### References:
* [StackOverFlow- Color Nodes in rpart Tree](https://stackoverflow.com/questions/31836405/color-nodes-in-rpart-tree)
* [DataCamp - Decision Trees R](https://www.datacamp.com/tutorial/decision-trees-R)
* [StackOverFlow - Display More Nodes in Decision Tree in R](https://stackoverflow.com/questions/43671205/display-more-nodes-in-decision-tree-in-r)
* [Guru99 - Decision Trees](https://www.guru99.com/r-decision-trees.html)

-----------------------------------------------------------------------------------------------------------------------------------


##### For code used | not used in this assignment see [GitHub](https://github.com/letisalba/Data-622/tree/master/Homework-1).
```{r, echo=FALSE}
# other small and large dataset's to consider
# small_df2 <- read.csv("https://raw.githubusercontent.com/letisalba/Data-622/master/Homework-1/csv/1000%20Sales%20Records.csv")
# large_df2 <- read.csv("https://raw.githubusercontent.com/letisalba/Data-622/master/Homework-1/csv/10000%20Sales%20Records.csv")

# # Prepare the dataset for ggplot2
# small_df <- small_df %>%
#   pivot_longer(cols = c(Region, Country, Item.Type, Sales.Channel, Order.Priority, Order.Date, Order.ID, Ship.Date, Units.Sold, Unit.Price, Unit.Cost, Total.Revenue, Total.Cost, Total.Profit), 
#                names_to = "Names", 
#                values_to = "Values")
# 
#  #pivot_longer(cols = c(Region, Country, Item.Type, Sales.Channel, Order.Priority, Order.Date, Order.ID, Ship.Date, Units.Sold, Unit.Price, Unit.Cost, Total.Revenue, Total.Cost, Total.Profit)#everything(),
#               #names_to = "variable",
#               #values_to = "value")
# 
# # Create a histogram for all numeric variables in one plot
# small_df_histograms <- ggplot(small_df, aes(x = value)) +
#  geom_histogram(bins = 30, color = "black", fill = "lightblue") +
#  facet_wrap(~variable, scales = "free", ncol = 4) +
#  labs(title = "Histograms of Small Dataset",
#       x = "Value",
#       y = "Frequency") +
#  theme_minimal()
# 
# # Plot the histograms
# print(small_df_histograms)

# Data Preparation
# # small data set 2
# small_df2$Region <- as.factor(small_df2$Region)
# small_df2$Country <- as.factor(small_df2$Country)
# small_df2$Item.Type <- as.factor(small_df2$Item.Type)
# small_df2$Sales.Channel <- as.factor(small_df2$Sales.Channel)
# small_df2$Order.Priority <- as.factor(small_df2$Order.Priority)
# small_df2$Order.Date <- as.Date(small_df2$Order.Date, "%m/%d/%Y")
# small_df2$Ship.Date <- as.Date(small_df2$Ship.Date, "%m/%d/%Y")
# 
# # large data set 2
# large_df2$Region <- as.factor(large_df2$Region)
# large_df2$Country <- as.factor(large_df2$Country)
# large_df2$Item.Type <- as.factor(large_df2$Item.Type)
# large_df2$Sales.Channel <- as.factor(large_df2$Sales.Channel)
# large_df2$Order.Priority <- as.factor(large_df2$Order.Priority)
# large_df2$Order.Date <- as.Date(large_df2$Order.Date, "%m/%d/%Y")
# large_df2$Ship.Date <- as.Date(large_df2$Ship.Date, "%m/%d/%Y")

# set.seed(213)
# 
# # small data set
# small_df2_split <- initial_split(small_df2, prop = 0.75)
# small_train2 <- training(small_df2_split)
# small_test2 <- testing(small_df2_split)
# 
# # large data set
# large_df2_split <- initial_split(large_df2, prop = 0.75)
# large_train2 <- training(large_df2_split)
# large_test2 <- testing(large_df2_split)

# small_df2_model <- rpart(small_df2 ~ ., method = "class", data = small_train2)
# 
# prp(small_df2_model, extra=1, faclen=0,  nn=T, box.palette="Blues")

# small_df2_prediction <- predict(small_df2_model, small_test2, type = "class")
# small_df2_prediction <- table(small_test2$Order.Priority, small_df2_prediction)
# small_df2_prediction

# sum(diag(small_df2_prediction)) / nrow(small_test2)

# large_df2_model <- rpart(Order.Priority ~ Region + Item.Type + Sales.Channel + Order.Date + Order.ID + Ship.Date + Units.Sold + Total.Revenue + Total.Cost + Total.Profit , method = "class", data = large_train2)
# 
# prp(large_df2_model, extra=1, faclen=0,  nn=T, box.palette="Blues")

# large_df2_model <- rpart(Order.Priority ~ Region + Item.Type + Sales.Channel + Order.Date + Order.ID + Ship.Date + Units.Sold + Total.Revenue + Total.Cost + Total.Profit , method = "class", data = large_train2, control=rpart.control(minsplit=2, minbucket=1, cp=0.001))
# 
# prp(large_df2_model, extra=1, faclen=0,  nn=T, box.palette="Blues")

# large_df2_prediction <- predict(large_df2_model, large_test2, type = "class")
# large_df2_prediction <- table(large_test2$Order.Priority, large_df2_prediction)
# large_df2_prediction

# sum(diag(large_df2_prediction)) / nrow(large_test2)

# # Create a decision tree model specification for small data set
# tree_spec_small <- decision_tree() %>%
#  set_engine("rpart") %>%
#  set_mode("regression")
# 
# # Fit the model to the training data
# tree_fit_small <- tree_spec_small %>%
#  fit(Units.Sold ~ ., data = small_train)
# 
# # Create a decision tree model specification for large data set
# tree_spec_large <- decision_tree() %>%
#  set_engine("rpart") %>%
#  set_mode("regression")
# 
# # Fit the model to the training data
# tree_fit_large <- tree_spec_large %>%
#  fit(Units.Sold ~ ., data = large_train)

# # Make predictions on the testing data for the small data set
# small_predictions <- tree_fit_small %>%
#  predict(small_test) %>%
#  pull(.pred)
# 
# # Calculate RMSE and R-squared for the small data set
# small_metrics <- metric_set(rmse, rsq)
# small_model_performance <- small_test %>%
#  mutate(small_predictions = small_predictions) %>%
#  small_metrics(truth = Units.Sold, estimate = small_predictions)
# 
# print(small_model_performance)
# 
# # Make predictions on the testing data for the large data set
# large_predictions <- tree_fit_large %>%
#  predict(large_test) %>%
#  pull(.pred)
# 
# # Calculate RMSE and R-squared for the large data set
# large_metrics <- metric_set(rmse, rsq)
# large_model_performance <- large_test %>%
#  mutate(large_predictions = large_predictions) %>%
#  large_metrics(truth = Units.Sold, estimate = large_predictions)
# 
# print(large_model_performance)

# Plot the decision tree for small data set
# rpart.plot(tree_fit_small$fit, type = 4, extra = 101, under = TRUE, cex = 0.8, box.palette = "auto")

# # Plot the decision tree for large data set
# rpart.plot(tree_fit_large$fit, type = 4, extra = 101, under = TRUE, cex = 0.8, box.palette = "auto")

# rules_small <- rpart.rules(tree_fit_small$fit)
# print(rules_small)

# rules_large <- rpart.rules(tree_fit_large$fit)
# print(rules_large)
```
